---
layout:     post
title:      Introducción
date:       2020-01-01 12:31:19
summary:    Material introductorio del curso de Deep Learning
categories: Curso Deep Learning
youtubeId1:  BASByOlqqkc
youtubeId2:  mDCxK2Pu0mA
youtubeId3:  eV-N1ozcZrk
---

#### Bienvenida
Un saludo a todos ustedes, febriles entusiastas de este fascinante campo de la inteligencia artificial que está revolucionando el mundo: el Deep Learning. En este blog compartiremos todo el material relevante del curso semestral de Deep Learning, dictado por el Dr. Jorge Pérez de la Universidad de Chile. Este es un curso principalmente teórico, excepto por 5 tareas que pondrán a prueba tu aprendizaje y que podrás encontrar al final de cada sección.

Aunque algunas clases te parecerán difíciles, puede serte de ayuda echar un repaso a los requisitos mínimos del curso:

-Álgebra Lineal

-Cálculo

-Estructuras de datos

-Programación en Python

Así mismo, si te interesa complementar las clases, te recomendamos que no dejes de visitar blogs, tutoriales y apps sobre el tema.

Sin más, esperamos que este material te sea de mucha utilidad, puedes consultarlo cuando quieras. :heart:

#### Clase 1: Introducción, IA vs ML vs DL, ¿Por qué DL ahora?
En esta clase daremos un vistazo general al Deep Learning y cómo se posiciona en relación a las distintas ramas de la Inteligencia Artificial.

Dificultad: :hatching_chick::egg::egg::egg::egg:
{% include youtubePlayer.html id=page.youtubeId1 %}


#### Clase 2: Perceptrón, funciones de activación, y representación matricial
El perceptrón es la célula básica de lo que conocemos de manera clásica como red neuronal, en esta clase aprenderemos por qué funciona. Además, descubriremos cómo emular el potencial de acción de redes neuronales biológicas (aunque es mejor que no te lo tomes tan literal). Por último, llevaremos todo esto a lenguaje matemático y grafos de computación :monkey_face:.

Dificultad: :hatching_chick::hatching_chick::egg::egg::egg:
{% include youtubePlayer.html id=page.youtubeId2 %}

#### Clase 3: UAT, Redes Feed-Forward, y función de salida (softmax)
En esta clase terminaremos de ver la estructura básica de una red neuronal, comenzando con un curioso teorema que establece el poder de aproximación casi ilimitado de las redes neuronales produndas. Por último estudiaremos cómo fluye la información en una red neuronal y el concepto de función de salida.

Dificultad: :hatching_chick::hatching_chick::egg::egg::egg:
{% include youtubePlayer.html id=page.youtubeId3 %}

#### Tarea 1 
[Ir al Notebook](https://colab.research.google.com/drive/1aeuSRjj_kQ_uFEBSJ9bRuyr4G4MY4FAi)